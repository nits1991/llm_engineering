{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d15d8294-3328-4e07-ad16-8a03e9bbfdb9",
   "metadata": {},
   "source": [
    "# YOUR FIRST LAB\n",
    "### Please read this section. This is valuable to get you prepared, even if it's a long read -- it's important stuff.\n",
    "\n",
    "### Also, be sure to read [README.md](../README.md)! More info about the updated videos in the README and [top of the course resources in purple](https://edwarddonner.com/2024/11/13/llm-engineering-resources/)\n",
    "\n",
    "## Your first Frontier LLM Project\n",
    "\n",
    "By the end of this course, you will have built an autonomous Agentic AI solution with 7 agents that collaborate to solve a business problem. All in good time! We will start with something smaller...\n",
    "\n",
    "Our goal is to code a new kind of Web Browser. Give it a URL, and it will respond with a summary. The Reader's Digest of the internet!!\n",
    "\n",
    "Before starting, you should have completed the setup linked in the README.\n",
    "\n",
    "### If you're new to working in \"Notebooks\" (also known as Labs or Jupyter Lab)\n",
    "\n",
    "Welcome to the wonderful world of Data Science experimentation! Simply click in each \"cell\" with code in it, such as the cell immediately below this text, and hit Shift+Return to execute that cell. Be sure to run every cell, starting at the top, in order.\n",
    "\n",
    "Please look in the [Guides folder](../guides/01_intro.ipynb) for all the guides.\n",
    "\n",
    "## I am here to help\n",
    "\n",
    "If you have any problems at all, please do reach out.  \n",
    "I'm available through the platform, or at ed@edwarddonner.com, or at https://www.linkedin.com/in/eddonner/ if you'd like to connect (and I love connecting!)  \n",
    "And this is new to me, but I'm also trying out X at [@edwarddonner](https://x.com/edwarddonner) - if you're on X, please show me how it's done üòÇ  \n",
    "\n",
    "## More troubleshooting\n",
    "\n",
    "Please see the [troubleshooting](../setup/troubleshooting.ipynb) notebook in the setup folder to diagnose and fix common problems. At the very end of it is a diagnostics script with some useful debug info.\n",
    "\n",
    "## If this is old hat!\n",
    "\n",
    "If you're already comfortable with today's material, please hang in there; you can move swiftly through the first few labs - we will get much more in depth as the weeks progress. Ultimately we will fine-tune our own LLM to compete with OpenAI!\n",
    "\n",
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/important.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#900;\">Please read - important note</h2>\n",
    "            <span style=\"color:#900;\">The way I collaborate with you may be different to other courses you've taken. I prefer not to type code while you watch. Rather, I execute Jupyter Labs, like this, and give you an intuition for what's going on. My suggestion is that you carefully execute this yourself, <b>after</b> watching the lecture. Add print statements to understand what's going on, and then come up with your own variations. If you have a Github account, use this to showcase your variations. Not only is this essential practice, but it demonstrates your skills to others, including perhaps future clients or employers...</span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/resources.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#f71;\">This code is a live resource - keep an eye out for my emails</h2>\n",
    "            <span style=\"color:#f71;\">I push updates to the code regularly. As people ask questions, I add more examples or improved commentary. As a result, you'll notice that the code below isn't identical to the videos. Everything from the videos is here; but I've also added better explanations and new models like DeepSeek. Consider this like an interactive book.<br/><br/>\n",
    "                I try to send emails regularly with important updates related to the course. You can find this in the 'Announcements' section of Udemy in the left sidebar. You can also choose to receive my emails via your Notification Settings in Udemy. I'm respectful of your inbox and always try to add value with my emails!\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/business.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#181;\">Business value of these exercises</h2>\n",
    "            <span style=\"color:#181;\">A final thought. While I've designed these notebooks to be educational, I've also tried to make them enjoyable. We'll do fun things like have LLMs tell jokes and argue with each other. But fundamentally, my goal is to teach skills you can apply in business. I'll explain business implications as we go, and it's worth keeping this in mind: as you build experience with models and techniques, think of ways you could put this into action at work today. Please do contact me if you'd like to discuss more or if you have ideas to bounce off me.</span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f28feb",
   "metadata": {},
   "source": [
    "### If necessary, install Cursor Extensions\n",
    "\n",
    "1. From the View menu, select Extensions\n",
    "2. Search for Python\n",
    "3. Click on \"Python\" made by \"ms-python\" and select Install if not already installed\n",
    "4. Search for Jupyter\n",
    "5. Click on \"Jupyter\" made by \"ms-toolsai\" and select Install of not already installed\n",
    "\n",
    "\n",
    "### Next Select the Kernel\n",
    "\n",
    "Click on \"Select Kernel\" on the Top Right\n",
    "\n",
    "Choose \"Python Environments...\"\n",
    "\n",
    "Then choose the one that looks like `.venv (Python 3.12.x) .venv/bin/python` - it should be marked as \"Recommended\" and have a big star next to it.\n",
    "\n",
    "Any problems with this? Head over to the troubleshooting.\n",
    "\n",
    "### Note: you'll need to set the Kernel with every notebook.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e2a9393-7767-488e-a8bf-27c12dca35bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os # for environment variables and files handling\n",
    "from dotenv import load_dotenv # to load environment variables from a .env file\n",
    "from scraper import fetch_website_contents # custom module to fetch website contents and metadata and parse them and return as text and images are ignored\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "# If you get an error running this cell, then please head over to the troubleshooting notebook!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6900b2a8-6384-4316-8aaa-5e519fca4254",
   "metadata": {},
   "source": [
    "# Connecting to OpenAI (or Ollama)\n",
    "\n",
    "The next cell is where we load in the environment variables in your `.env` file and connect to OpenAI.  \n",
    "\n",
    "If you'd like to use free Ollama instead, please see the README section \"Free Alternative to Paid APIs\", and if you're not sure how to do this, there's a full solution in the solutions folder (day1_with_ollama.ipynb).\n",
    "\n",
    "## Troubleshooting if you have problems:\n",
    "\n",
    "If you get a \"Name Error\" - have you run all cells from the top down? Head over to the Python Foundations guide for a bulletproof way to find and fix all Name Errors.\n",
    "\n",
    "If that doesn't fix it, head over to the [troubleshooting](../setup/troubleshooting.ipynb) notebook for step by step code to identify the root cause and fix it!\n",
    "\n",
    "Or, contact me! Message me or email ed@edwarddonner.com and we will get this to work.\n",
    "\n",
    "Any concerns about API costs? See my notes in the README - costs should be minimal, and you can control it at every point. You can also use Ollama as a free alternative, which we discuss during Day 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b87cadb-d513-4303-baee-a37b6f938e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key found and looks good so far!\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables in a file called .env\n",
    "\n",
    "load_dotenv(override=True) # override existing environment variables if any\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Check the key\n",
    "\n",
    "if not api_key:\n",
    "    print(\"No API key was found - please head over to the troubleshooting notebook in this folder to identify & fix!\")\n",
    "elif not api_key.startswith(\"sk-proj-\"):\n",
    "    print(\"An API key was found, but it doesn't start sk-proj-; please check you're using the right key - see troubleshooting notebook\")\n",
    "elif api_key.strip() != api_key:\n",
    "    print(\"An API key was found, but it looks like it might have space or tab characters at the start or end - please remove them - see troubleshooting notebook\")\n",
    "else:\n",
    "    print(\"API key found and looks good so far!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442fc84b-0815-4f40-99ab-d9a5da6bda91",
   "metadata": {},
   "source": [
    "# Let's make a quick call to a Frontier model to get started, as a preview!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf613e7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': 'hey there, how are you? This is my first message to you from llm engineering bootcamp.'},\n",
       " {'role': 'system', 'content': 'You are a helpful assistant'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_message = \"hey there, how are you? This is my first message to you from llm engineering bootcamp.\"\n",
    "\n",
    "# this is the format that the OpenAI API expects, array of messages with role and content\n",
    "# role can be user, system, assistant\n",
    "# system messages are used to set the behavior of the assistant\n",
    "my_messages= [\n",
    "\n",
    "    {\"role\": \"user\", \"content\": my_message},\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant\"}\n",
    "\n",
    "    \n",
    "]\n",
    "\n",
    "my_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58394bf-1e45-46af-9bfd-01e24da6f49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To give you a preview -- calling OpenAI with these messages is this easy. Any problems, head over to the Troubleshooting notebook.\n",
    "\n",
    "message = \"Hello, GPT! This is my first ever message to you! Hi!\"\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": message}]\n",
    "\n",
    "messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f4877bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hey! I‚Äôm glad you‚Äôre here, and congrats on starting the bootcamp. I‚Äôm doing well‚Äîready to help you with anything you want to learn or build in LLM engineering.\\n\\nWhat would you like to start with? If you‚Äôre not sure, here are common starter topics (we can pick one and go deep):\\n\\n- Prompt engineering basics: crafting prompts, system messages, few-shot vs zero-shot.\\n- Model evaluation: baselines, metrics, human-in-the-loop evaluation, reproducibility.\\n- Data pipelines: collecting, cleaning, deduplicating, labeling data.\\n- Fine-tuning vs adapters: when to fine-tune, LoRA/adapter approaches, efficiency.\\n- Safety and bias: guardrails, red-teaming prompts, content policy checks.\\n- Deployment basics: serving, latency tricks, monitoring, versioning.\\n\\nIf you share your stack (Python version, frameworks like PyTorch/TensorFlow, any libs you‚Äôre using) and your goals (e.g., ‚Äúbuild a prompt-engineered chatbot,‚Äù ‚Äúevaluate models for a domain-specific task‚Äù), I‚Äôll tailor a plan and even run through a quick hands-on example with you. \\n\\nWould you like a quick primer on one topic, or jump into a small project idea right away?'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "openai = OpenAI()\n",
    "# chat completion API call\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-5-nano\", # use the smallest model for testing\n",
    "    messages=my_messages # this is where we pass the messages array\n",
    ")\n",
    "# choice is the array of responses, we just asked for one, so we take the first one, why multiple? because you can ask for multiple completions in one go!\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08330159",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai = OpenAI()\n",
    "\n",
    "response = openai.chat.completions.create(model=\"gpt-5-nano\", messages=messages)\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa190e5-cb31-456a-96cc-db109919cd78",
   "metadata": {},
   "source": [
    "## OK onwards with our first project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ef960cf-6dc2-4cda-afb3-b38be12f4c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Home - Edward Donner\n",
      "\n",
      "Home\n",
      "Connect Four\n",
      "Outsmart\n",
      "An arena that pits LLMs against each other in a battle of diplomacy and deviousness\n",
      "About\n",
      "Posts\n",
      "Well, hi there.\n",
      "I‚Äôm Ed. I like writing code and experimenting with LLMs, and hopefully you‚Äôre here because you do too. I also enjoy DJing (but I‚Äôm badly out of practice), amateur electronic music production (\n",
      "very\n",
      "amateur) and losing myself in\n",
      "Hacker News\n",
      ", nodding my head sagely to things I only half understand.\n",
      "I‚Äôm the co-founder and CTO of\n",
      "Nebula.io\n",
      ". We‚Äôre applying AI to a field where it can make a massive, positive impact: helping people discover their potential and pursue their reason for being. Recruiters use our product today to source, understand, engage and manage talent. I‚Äôm previously the founder and CEO of AI startup untapt,\n",
      "acquired in 2021\n",
      ".\n",
      "We work with groundbreaking, proprietary LLMs verticalized for talent, we‚Äôve\n",
      "patented\n",
      "our matching model, and our award-winning platform has happy customers and tons of press coverage.\n",
      "Connect\n",
      "with me for more!\n",
      "November 11, 2025\n",
      "The Unique Energy of an AI Live Event\n",
      "September 15, 2025\n",
      "AI in Production: Gen AI and Agentic AI on AWS at scale\n",
      "May 28, 2025\n",
      "Be an AI Engineer and Leader: The Curriculum\n",
      "May 18, 2025\n",
      "2025 AI Executive Briefing\n",
      "Navigation\n",
      "Home\n",
      "Connect Four\n",
      "Outsmart\n",
      "An arena that pits LLMs against each other in a battle of diplomacy and deviousness\n",
      "About\n",
      "Posts\n",
      "Get in touch\n",
      "ed [at] edwarddonner [dot] com\n",
      "www.edwarddonner.com\n",
      "Follow me\n",
      "LinkedIn\n",
      "Twitter\n",
      "Facebook\n",
      "Subscribe to newsletter\n",
      "Type your email‚Ä¶\n",
      "Subscribe\n"
     ]
    }
   ],
   "source": [
    "# Let's try out this utility\n",
    "\n",
    "ed = fetch_website_contents(\"https://edwarddonner.com\")\n",
    "print(ed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a478a0c-2c53-48ff-869c-4d08199931e1",
   "metadata": {},
   "source": [
    "## Types of prompts\n",
    "\n",
    "You may know this already - but if not, you will get very familiar with it!\n",
    "\n",
    "Models like GPT have been trained to receive instructions in a particular way.\n",
    "\n",
    "They expect to receive:\n",
    "\n",
    "**A system prompt** that tells them what task they are performing and what tone they should use\n",
    "\n",
    "**A user prompt** -- the conversation starter that they should reply to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdb8417-c5dc-44bc-9bee-2e059d162699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our system prompt - you can experiment with this later, changing the last sentence to 'Respond in markdown in Spanish.\"\n",
    "\n",
    "# System prompt is used to set the behavior of the assistant, setting the scene for it. the context it needs to respond appropriately. It is the mission that is assigned to the LLM, it will significantly impact the responses you get back and change the tone, style and content of the responses.\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "You are a snarkyassistant that analyzes the contents of a website,\n",
    "and provides a short, snarky, humorous summary, ignoring text that might be navigation related.\n",
    "Respond in markdown. Do not wrap the markdown in a code block - respond just with the markdown.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a4c3ab",
   "metadata": {},
   "source": [
    "# System Prompts - The Foundation of AI Behavior\n",
    "\n",
    "System prompts are arguably the most important part of working with LLMs. They set the **personality**, **expertise**, **tone**, and **behavior** of your AI assistant. Think of them as the \"character sheet\" for your AI.\n",
    "\n",
    "## Key Components of Effective System Prompts\n",
    "\n",
    "### 1. **Role Definition** - Who is the AI?\n",
    "- \"You are a helpful assistant\"\n",
    "- \"You are an expert Python developer\"\n",
    "- \"You are a friendly customer service representative\"\n",
    "\n",
    "### 2. **Behavior Instructions** - How should it act?\n",
    "- \"Be concise and direct\"\n",
    "- \"Use a casual, friendly tone\"\n",
    "- \"Always ask clarifying questions before providing solutions\"\n",
    "\n",
    "### 3. **Output Format** - How should responses be structured?\n",
    "- \"Respond in markdown format\"\n",
    "- \"Provide answers in JSON format\"\n",
    "- \"Give step-by-step explanations\"\n",
    "\n",
    "### 4. **Constraints** - What should it avoid or include?\n",
    "- \"Do not make assumptions about user requirements\"\n",
    "- \"Always provide code examples when explaining concepts\"\n",
    "- \"If you're unsure, say so rather than guessing\"\n",
    "\n",
    "## Examples by Use Case\n",
    "\n",
    "Let's explore different system prompt patterns for various business applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae96cb32",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# System Prompt Examples - Let's see them in action!\u001b[39;00m\n\u001b[32m      2\u001b[39m \n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Example 1: Technical Documentation Assistant\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m technical_system_prompt = \u001b[33;43m\"\"\"\u001b[39;49m\n\u001b[32m      5\u001b[39m \u001b[33;43mYou are a senior technical writer and software architect with expertise in Python, web development, and API design.\u001b[39;49m\n\u001b[32m      6\u001b[39m \u001b[33;43mYour role is to explain complex technical concepts in clear, accessible language.\u001b[39;49m\n\u001b[32m      7\u001b[39m \n\u001b[32m      8\u001b[39m \u001b[33;43mGuidelines:\u001b[39;49m\n\u001b[32m      9\u001b[39m \u001b[33;43m- Break down complex topics into digestible steps\u001b[39;49m\n\u001b[32m     10\u001b[39m \u001b[33;43m- Always provide practical code examples\u001b[39;49m\n\u001b[32m     11\u001b[39m \u001b[33;43m- Use analogies when helpful to explain abstract concepts\u001b[39;49m\n\u001b[32m     12\u001b[39m \u001b[33;43m- Structure responses with clear headings and bullet points\u001b[39;49m\n\u001b[32m     13\u001b[39m \u001b[33;43m- If a concept has multiple approaches, explain the trade-offs\u001b[39;49m\n\u001b[32m     14\u001b[39m \u001b[33;43m- When unsure about specific implementation details, acknowledge limitations\u001b[39;49m\n\u001b[32m     15\u001b[39m \n\u001b[32m     16\u001b[39m \u001b[33;43mResponse format: Use markdown with code blocks, headers, and bullet points for clarity.\u001b[39;49m\n\u001b[32m     17\u001b[39m \u001b[33;43m\"\"\"\u001b[39;49m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Example 2: Business Analysis Assistant\u001b[39;00m\n\u001b[32m     20\u001b[39m business_system_prompt = \u001b[33m\"\"\"\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[33mYou are an experienced business analyst and strategy consultant with 15+ years of experience.\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[33mYou specialize in helping companies identify opportunities, analyze market trends, and make data-driven decisions.\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m     32\u001b[39m \u001b[33mFormat: Provide structured analysis with clear recommendations and next steps.\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<stringsource>:69\u001b[39m, in \u001b[36mcfunc.to_py.__Pyx_CFunc_b0409f__29_pydevd_sys_monitoring_cython_object__lParen__etc_to_py_4code_4line.wrap\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_pydevd_sys_monitoring\\\\_pydevd_sys_monitoring_cython.pyx:1481\u001b[39m, in \u001b[36m_pydevd_sys_monitoring_cython._line_event\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_pydevd_sys_monitoring\\\\_pydevd_sys_monitoring_cython.pyx:1523\u001b[39m, in \u001b[36m_pydevd_sys_monitoring_cython._internal_line_event\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_pydevd_sys_monitoring\\\\_pydevd_sys_monitoring_cython.pyx:1324\u001b[39m, in \u001b[36m_pydevd_sys_monitoring_cython._stop_on_breakpoint\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_pydevd_sys_monitoring\\\\_pydevd_sys_monitoring_cython.pyx:1961\u001b[39m, in \u001b[36m_pydevd_sys_monitoring_cython._do_wait_suspend\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/llm_learning_2025_bootcamp/llm_engineering/.venv/lib/python3.12/site-packages/debugpy/_vendored/pydevd/pydevd.py:2188\u001b[39m, in \u001b[36mPyDB.do_wait_suspend\u001b[39m\u001b[34m(self, thread, frame, event, arg, exception_type)\u001b[39m\n\u001b[32m   2185\u001b[39m             from_this_thread.append(frame_custom_thread_id)\n\u001b[32m   2187\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._threads_suspended_single_notification.notify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[32m-> \u001b[39m\u001b[32m2188\u001b[39m         keep_suspended = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrace_suspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2190\u001b[39m frames_list = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2192\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[32m   2193\u001b[39m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/llm_learning_2025_bootcamp/llm_engineering/.venv/lib/python3.12/site-packages/debugpy/_vendored/pydevd/pydevd.py:2257\u001b[39m, in \u001b[36mPyDB._do_wait_suspend\u001b[39m\u001b[34m(self, thread, frame, event, arg, trace_suspend_type, from_this_thread, frames_tracker)\u001b[39m\n\u001b[32m   2254\u001b[39m                 queue.put(internal_cmd)\n\u001b[32m   2255\u001b[39m                 wait_timeout = TIMEOUT_FAST\n\u001b[32m-> \u001b[39m\u001b[32m2257\u001b[39m         \u001b[43mnotify_event\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2258\u001b[39m         notify_event.clear()\n\u001b[32m   2260\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.0/lib/python3.12/threading.py:634\u001b[39m, in \u001b[36mEvent.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    632\u001b[39m signaled = \u001b[38;5;28mself\u001b[39m._flag\n\u001b[32m    633\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[32m--> \u001b[39m\u001b[32m634\u001b[39m     signaled = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cond\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    635\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.0/lib/python3.12/threading.py:338\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    337\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout > \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m338\u001b[39m         gotit = \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    339\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    340\u001b[39m         gotit = waiter.acquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# System Prompt Examples - Let's see them in action!\n",
    "\n",
    "# Example 1: Technical Documentation Assistant\n",
    "technical_system_prompt = \"\"\"\n",
    "You are a senior technical writer and software architect with expertise in Python, web development, and API design.\n",
    "Your role is to explain complex technical concepts in clear, accessible language.\n",
    "\n",
    "Guidelines:\n",
    "- Break down complex topics into digestible steps\n",
    "- Always provide practical code examples\n",
    "- Use analogies when helpful to explain abstract concepts\n",
    "- Structure responses with clear headings and bullet points\n",
    "- If a concept has multiple approaches, explain the trade-offs\n",
    "- When unsure about specific implementation details, acknowledge limitations\n",
    "\n",
    "Response format: Use markdown with code blocks, headers, and bullet points for clarity.\n",
    "\"\"\"\n",
    "\n",
    "# Example 2: Business Analysis Assistant\n",
    "business_system_prompt = \"\"\"\n",
    "You are an experienced business analyst and strategy consultant with 15+ years of experience.\n",
    "You specialize in helping companies identify opportunities, analyze market trends, and make data-driven decisions.\n",
    "\n",
    "Your approach:\n",
    "- Always start by understanding the business context and goals\n",
    "- Provide actionable insights backed by reasoning\n",
    "- Consider both short-term and long-term implications\n",
    "- Identify potential risks and mitigation strategies\n",
    "- Use frameworks like SWOT, Porter's Five Forces when relevant\n",
    "- Be direct and professional, but approachable\n",
    "\n",
    "Format: Provide structured analysis with clear recommendations and next steps.\n",
    "\"\"\"\n",
    "\n",
    "# Example 3: Creative Writing Assistant\n",
    "creative_system_prompt = \"\"\"\n",
    "You are a creative writing mentor with expertise in storytelling, character development, and narrative structure.\n",
    "You help writers at all levels improve their craft through constructive feedback and creative exercises.\n",
    "\n",
    "Your style:\n",
    "- Be encouraging and supportive while providing honest feedback\n",
    "- Offer specific, actionable suggestions for improvement\n",
    "- Help brainstorm ideas when writers face creative blocks\n",
    "- Explain writing techniques with examples from literature\n",
    "- Adapt your communication style to the writer's experience level\n",
    "- Focus on both technical craft and creative expression\n",
    "\n",
    "Always ask clarifying questions about genre, audience, and goals before providing detailed feedback.\n",
    "\"\"\"\n",
    "\n",
    "print(\"System prompt examples defined! Let's test them out...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77c0349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's test different system prompts with the same user question\n",
    "\n",
    "def test_system_prompt(system_prompt, user_question, description):\n",
    "    \"\"\"\n",
    "    Helper function to test different system prompts with the same user input\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Testing: {description}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_question}\n",
    "    ]\n",
    "    \n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        messages=messages,\n",
    "        max_tokens=300  # Keep responses concise for comparison\n",
    "    )\n",
    "    \n",
    "    result = response.choices[0].message.content\n",
    "    print(result)\n",
    "    return result\n",
    "\n",
    "# Let's test with a common user question\n",
    "user_question = \"I'm building a web application and need to handle user authentication. What should I consider?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce01f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 1: Technical Documentation Assistant\n",
    "test_system_prompt(technical_system_prompt, user_question, \"Technical Documentation Assistant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3459f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 2: Business Analysis Assistant\n",
    "test_system_prompt(business_system_prompt, user_question, \"Business Analysis Assistant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744154d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 3: Compare with a basic system prompt\n",
    "basic_system_prompt = \"You are a helpful assistant.\"\n",
    "\n",
    "test_system_prompt(basic_system_prompt, user_question, \"Basic System Prompt (for comparison)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6410e2c",
   "metadata": {},
   "source": [
    "## Advanced System Prompt Techniques\n",
    "\n",
    "### 1. **Few-Shot Learning in System Prompts**\n",
    "Include examples of desired input/output behavior directly in the system prompt.\n",
    "\n",
    "### 2. **Persona + Context + Constraints Pattern**\n",
    "```\n",
    "You are [PERSONA] with [EXPERTISE/BACKGROUND].\n",
    "You are currently [CONTEXT/SITUATION].\n",
    "Your task is to [SPECIFIC GOAL].\n",
    "\n",
    "Guidelines:\n",
    "- [SPECIFIC BEHAVIOR 1]\n",
    "- [SPECIFIC BEHAVIOR 2]\n",
    "- [FORMAT REQUIREMENTS]\n",
    "\n",
    "Constraints:\n",
    "- [WHAT TO AVOID]\n",
    "- [LIMITATIONS]\n",
    "```\n",
    "\n",
    "### 3. **Chain of Thought Prompting**\n",
    "Instruct the AI to think step-by-step before providing final answers.\n",
    "\n",
    "### 4. **Temperature Control Through Prompts**\n",
    "- For creative tasks: \"Be creative and explore multiple possibilities\"\n",
    "- For factual tasks: \"Be precise and stick to verified information\"\n",
    "\n",
    "Let's see these techniques in action!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b552da21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced Technique 1: Few-Shot Learning System Prompt\n",
    "few_shot_system_prompt = \"\"\"\n",
    "You are an expert code reviewer who provides constructive feedback on code quality, security, and best practices.\n",
    "\n",
    "Here are examples of how you should respond:\n",
    "\n",
    "Example 1:\n",
    "User: \"def login(user, pwd): return user == 'admin' and pwd == '123'\"\n",
    "Your response: \n",
    "**Security Issues:**\n",
    "- Hardcoded credentials are a major security vulnerability\n",
    "- Plain text password comparison\n",
    "**Improvements:**\n",
    "- Use environment variables for admin credentials\n",
    "- Implement proper password hashing (bcrypt/Argon2)\n",
    "- Add input validation\n",
    "\n",
    "Example 2:\n",
    "User: \"for i in range(len(items)): print(items[i])\"\n",
    "Your response:\n",
    "**Style Issues:**\n",
    "- Unpythonic loop structure\n",
    "**Improvements:**\n",
    "- Use: `for item in items: print(item)` for better readability\n",
    "- Or with index: `for i, item in enumerate(items): print(f\"{i}: {item}\")`\n",
    "\n",
    "Now apply this same detailed, constructive approach to any code submitted.\n",
    "\"\"\"\n",
    "\n",
    "# Advanced Technique 2: Chain of Thought System Prompt\n",
    "chain_of_thought_prompt = \"\"\"\n",
    "You are a problem-solving assistant that helps break down complex problems into manageable steps.\n",
    "\n",
    "Your process:\n",
    "1. **Understanding**: First, rephrase the problem to confirm understanding\n",
    "2. **Analysis**: Identify the key components and requirements\n",
    "3. **Planning**: Outline a step-by-step approach\n",
    "4. **Solution**: Provide the detailed solution\n",
    "5. **Verification**: Suggest how to validate the solution\n",
    "\n",
    "Always show your thinking process before giving the final answer. Use clear headers for each step.\n",
    "\"\"\"\n",
    "\n",
    "print(\"Advanced system prompt techniques defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651820bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the Few-Shot Learning approach\n",
    "code_to_review = \"\"\"\n",
    "def calculate_total(items):\n",
    "    total = 0\n",
    "    for item in items:\n",
    "        total = total + item['price'] * item['quantity']\n",
    "    return total\n",
    "\"\"\"\n",
    "\n",
    "test_system_prompt(few_shot_system_prompt, f\"Review this code:\\n{code_to_review}\", \"Few-Shot Learning Code Reviewer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beeac945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Chain of Thought approach\n",
    "complex_problem = \"I need to build a recommendation system for an e-commerce site with 10,000 products and 50,000 users. What approach should I take?\"\n",
    "\n",
    "test_system_prompt(chain_of_thought_prompt, complex_problem, \"Chain of Thought Problem Solver\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a0c995",
   "metadata": {},
   "source": [
    "## Industry-Specific System Prompt Templates\n",
    "\n",
    "Here are some ready-to-use system prompt templates for different industries and use cases:\n",
    "\n",
    "### üè• Healthcare/Medical\n",
    "```python\n",
    "medical_system_prompt = \"\"\"\n",
    "You are a medical information assistant with extensive knowledge of healthcare practices and medical literature.\n",
    "IMPORTANT: You provide educational information only. Always recommend consulting qualified healthcare professionals for medical decisions.\n",
    "\n",
    "Guidelines:\n",
    "- Cite relevant medical studies when appropriate\n",
    "- Explain medical terms in accessible language\n",
    "- Include appropriate disclaimers about professional medical advice\n",
    "- Focus on evidence-based information\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "### üí∞ Financial Services\n",
    "```python\n",
    "financial_system_prompt = \"\"\"\n",
    "You are a financial analysis expert with deep knowledge of markets, investment strategies, and financial planning.\n",
    "DISCLAIMER: This is educational content, not personalized financial advice.\n",
    "\n",
    "Your approach:\n",
    "- Base recommendations on established financial principles\n",
    "- Consider risk tolerance and time horizons\n",
    "- Explain complex financial concepts clearly\n",
    "- Always mention the importance of diversification and professional consultation\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "### üéì Education/Training\n",
    "```python\n",
    "educational_system_prompt = \"\"\"\n",
    "You are an experienced educator and instructional designer specializing in adult learning.\n",
    "\n",
    "Your teaching philosophy:\n",
    "- Adapt explanations to the learner's current knowledge level\n",
    "- Use the Socratic method - ask questions to guide discovery\n",
    "- Provide multiple examples and analogies\n",
    "- Encourage critical thinking over memorization\n",
    "- Break complex topics into digestible chunks\n",
    "- Always check for understanding before moving to advanced concepts\n",
    "\"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7a37a8",
   "metadata": {},
   "source": [
    "## üéØ Your Turn - System Prompt Exercises\n",
    "\n",
    "Now it's time to practice! Try creating system prompts for these scenarios:\n",
    "\n",
    "### Exercise 1: Customer Service Chatbot\n",
    "Create a system prompt for a customer service chatbot that:\n",
    "- Is helpful and empathetic\n",
    "- Can escalate issues when needed\n",
    "- Maintains a professional but friendly tone\n",
    "- Follows company policies\n",
    "\n",
    "### Exercise 2: Content Marketing Assistant\n",
    "Design a system prompt for generating marketing content that:\n",
    "- Understands different brand voices\n",
    "- Creates engaging, non-salesy content\n",
    "- Considers target audience demographics\n",
    "- Follows content marketing best practices\n",
    "\n",
    "### Exercise 3: Data Analysis Assistant\n",
    "Build a system prompt for a data analyst that:\n",
    "- Asks clarifying questions about data context\n",
    "- Suggests appropriate visualizations\n",
    "- Explains statistical concepts clearly\n",
    "- Recommends next steps for analysis\n",
    "\n",
    "**Try implementing one of these in the cell below and test it!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35698a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üõ†Ô∏è Practice Area - Create Your Own System Prompt\n",
    "\n",
    "# Step 1: Choose your use case and define your system prompt\n",
    "my_custom_system_prompt = \"\"\"\n",
    "# Replace this with your own system prompt!\n",
    "# Choose one of the exercises above or create something entirely new\n",
    "# Remember to include: role, behavior, constraints, and output format\n",
    "\"\"\"\n",
    "\n",
    "# Step 2: Define a test user message\n",
    "my_test_message = \"Replace this with a relevant user message for your system prompt\"\n",
    "\n",
    "# Step 3: Test your system prompt\n",
    "# Uncomment the lines below when you're ready to test\n",
    "# test_system_prompt(my_custom_system_prompt, my_test_message, \"My Custom System Prompt\")\n",
    "\n",
    "print(\"Ready for your custom system prompt! Edit the variables above and uncomment the test line.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50394745",
   "metadata": {},
   "source": [
    "## üìö Key Takeaways: System Prompt Best Practices\n",
    "\n",
    "### ‚úÖ **DO:**\n",
    "- **Be Specific**: The more specific your instructions, the more consistent the results\n",
    "- **Set Clear Expectations**: Define exactly what you want the AI to do\n",
    "- **Include Examples**: Show the AI what good responses look like (few-shot learning)\n",
    "- **Define Output Format**: Specify if you want markdown, JSON, bullet points, etc.\n",
    "- **Add Constraints**: Tell the AI what NOT to do or include\n",
    "- **Consider Your Audience**: Tailor the language and complexity appropriately\n",
    "- **Test and Iterate**: Try different versions and see what works best\n",
    "\n",
    "### ‚ùå **DON'T:**\n",
    "- **Be Vague**: \"Be helpful\" is less effective than specific behavioral guidelines\n",
    "- **Overload with Instructions**: Too many rules can confuse the model\n",
    "- **Forget Context**: Consider what the AI knows and doesn't know\n",
    "- **Ignore Edge Cases**: Think about unusual inputs and how you want them handled\n",
    "- **Set Unrealistic Expectations**: AI has limitations - work within them\n",
    "- **Use Contradictory Instructions**: Ensure your guidelines don't conflict\n",
    "\n",
    "### üîÑ **System Prompt Iteration Process:**\n",
    "1. Start with a basic prompt\n",
    "2. Test with various inputs\n",
    "3. Identify failure modes or unwanted behaviors\n",
    "4. Refine the prompt to address issues\n",
    "5. Re-test and repeat\n",
    "\n",
    "### üí° **Pro Tips:**\n",
    "- Save successful system prompts for reuse\n",
    "- Version control your prompts (treat them like code!)\n",
    "- A/B test different versions to find what works best\n",
    "- Consider using prompt templates for consistency across projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0275b1b-7cfe-4f9d-abfa-7650d378da0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our user prompt\n",
    "\n",
    "user_prompt_prefix = \"\"\"\n",
    "Here are the contents of a website.\n",
    "Provide a short summary of this website.\n",
    "If it includes news or announcements, then summarize these too.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea211b5f-28e1-4a86-8e52-c0b7677cadcc",
   "metadata": {},
   "source": [
    "## Messages\n",
    "\n",
    "The API from OpenAI expects to receive messages in a particular structure.\n",
    "Many of the other APIs share this structure:\n",
    "\n",
    "### roles: system, user, assistant\n",
    "\n",
    "```python\n",
    "[\n",
    "    {\"role\": \"system\", \"content\": \"system message goes here\"},\n",
    "    {\"role\": \"user\", \"content\": \"user message goes here\"}\n",
    "]\n",
    "```\n",
    "To give you a preview, the next 2 cells make a rather simple call - we won't stretch the mighty GPT (yet!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f25dcd35-0cd0-4235-9f64-ac37ed9eaaa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ah, the classic! 2 + 2 equals 4. But if you‚Äôre still counting sheep or apples, I‚Äôll be here waiting‚Äîjust don‚Äôt forget to carry the 1!'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a humerous assistant\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is 2 + 2?\"}\n",
    "]\n",
    "\n",
    "response = openai.chat.completions.create(model=\"gpt-4.1-nano\", messages=messages)\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06e8d78-ce4c-4b05-aa8e-17050c82bb47",
   "metadata": {},
   "source": [
    "## And now let's build useful messages for GPT-4.1-mini, using a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0134dfa4-8299-48b5-b444-f2a8c3403c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how this function creates exactly the format above\n",
    "\n",
    "def messages_for(website):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt_prefix + website}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36478464-39ee-485c-9f3f-6a4e458dbc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try this out, and then try for a few more websites\n",
    "\n",
    "messages_for(ed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f49d46-bf55-4c3e-928f-68fc0bf715b0",
   "metadata": {},
   "source": [
    "## Time to bring it together - the API for OpenAI is very simple!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905b9919-aba7-45b5-ae65-81b3d1d78e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now: call the OpenAI API. You will get very familiar with this!\n",
    "\n",
    "def summarize(url):\n",
    "    website = fetch_website_contents(url)\n",
    "    response = openai.chat.completions.create(\n",
    "        model = \"gpt-4.1-mini\",\n",
    "        messages = messages_for(website)\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e38d41-dfa4-4b20-9c96-c46ea75d9fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize(\"https://edwarddonner.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d926d59-450e-4609-92ba-2d6f244f1342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to display this nicely in the output, using markdown\n",
    "\n",
    "def display_summary(url):\n",
    "    summary = summarize(url)\n",
    "    display(Markdown(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3018853a-445f-41ff-9560-d925d1774b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_summary(\"https://edwarddonner.com\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bcf6f4-adce-45e9-97ad-d9a5d7a3a624",
   "metadata": {},
   "source": [
    "# Let's try more websites\n",
    "\n",
    "Note that this will only work on websites that can be scraped using this simplistic approach.\n",
    "\n",
    "Websites that are rendered with Javascript, like React apps, won't show up. See the community-contributions folder for a Selenium implementation that gets around this. You'll need to read up on installing Selenium (ask ChatGPT!)\n",
    "\n",
    "Also Websites protected with CloudFront (and similar) may give 403 errors - many thanks Andy J for pointing this out.\n",
    "\n",
    "But many websites will work just fine!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d83403-a24c-44b5-84ac-961449b4008f",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_summary(\"https://cnn.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e9fd40-b354-4341-991e-863ef2e59db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_summary(\"https://anthropic.com\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c951be1a-7f1b-448f-af1f-845978e47e2c",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/business.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#181;\">Business applications</h2>\n",
    "            <span style=\"color:#181;\">In this exercise, you experienced calling the Cloud API of a Frontier Model (a leading model at the frontier of AI) for the first time. We will be using APIs like OpenAI at many stages in the course, in addition to building our own LLMs.\n",
    "\n",
    "More specifically, we've applied this to Summarization - a classic Gen AI use case to make a summary. This can be applied to any business vertical - summarizing the news, summarizing financial performance, summarizing a resume in a cover letter - the applications are limitless. Consider how you could apply Summarization in your business, and try prototyping a solution.</span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/important.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#900;\">Before you continue - now try yourself</h2>\n",
    "            <span style=\"color:#900;\">Use the cell below to make your own simple commercial example. Stick with the summarization use case for now. Here's an idea: write something that will take the contents of an email, and will suggest an appropriate short subject line for the email. That's the kind of feature that might be built into a commercial email tool.</span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00743dac-0e70-45b7-879a-d7293a6f68a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create your prompts\n",
    "\n",
    "system_prompt = \"something here\"\n",
    "user_prompt = \"\"\"\n",
    "    Lots of text\n",
    "    Can be pasted here\n",
    "\"\"\"\n",
    "\n",
    "# Step 2: Make the messages list\n",
    "\n",
    "messages = [] # fill this in\n",
    "\n",
    "# Step 3: Call OpenAI\n",
    "# response =\n",
    "\n",
    "# Step 4: print the result\n",
    "# print("
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ed9f14-b349-40e9-a42c-b367e77f8bda",
   "metadata": {},
   "source": [
    "## An extra exercise for those who enjoy web scraping\n",
    "\n",
    "You may notice that if you try `display_summary(\"https://openai.com\")` - it doesn't work! That's because OpenAI has a fancy website that uses Javascript. There are many ways around this that some of you might be familiar with. For example, Selenium is a hugely popular framework that runs a browser behind the scenes, renders the page, and allows you to query it. If you have experience with Selenium, Playwright or similar, then feel free to improve the Website class to use them. In the community-contributions folder, you'll find an example Selenium solution from a student (thank you!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f0fb1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eeab24dc-5f90-4570-b542-b0585aca3eb6",
   "metadata": {},
   "source": [
    "# Sharing your code\n",
    "\n",
    "I'd love it if you share your code afterwards so I can share it with others! You'll notice that some students have already made changes (including a Selenium implementation) which you will find in the community-contributions folder. If you'd like add your changes to that folder, submit a Pull Request with your new versions in that folder and I'll merge your changes.\n",
    "\n",
    "If you're not an expert with git (and I am not!) then GPT has given some nice instructions on how to submit a Pull Request. It's a bit of an involved process, but once you've done it once it's pretty clear. As a pro-tip: it's best if you clear the outputs of your Jupyter notebooks (Edit >> Clean outputs of all cells, and then Save) for clean notebooks.\n",
    "\n",
    "Here are good instructions courtesy of an AI friend:  \n",
    "https://chatgpt.com/share/677a9cb5-c64c-8012-99e0-e06e88afd293"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4484fcf-8b39-4c3f-9674-37970ed71988",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-engineering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
